{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e3e0ca",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "This notebook shows the code that has been develop to create, configure, train, and cross-validate the deep learning model for the Kaggle competition titled [Beyond Visible Spectrum: AI for Agriculture 2025](https://www.kaggle.com/competitions/beyond-visible-spectrum-ai-for-agriculture-2025/leaderboard)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba7507",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6892a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import v2\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Import custom libraries\n",
    "from utils.classification_utils import set_seeds\n",
    "from engines.regression import RegressionEngine\n",
    "from models.vision_transformer import SpectralViT, ViT\n",
    "from engines.schedulers import FixedLRSchedulerWrapper\n",
    "from engines.common import Common\n",
    "from dataloaders.hyperspectral_dataloaders import create_dataloaders, MeanStdNormalize, HyperspectralAugmentation\n",
    "\n",
    "# Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "import warnings\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.autograd.graph\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"onnxscript.converter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6555499",
   "metadata": {},
   "source": [
    "# 3. Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea443bb-470a-47e5-8f4d-341abf4e4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target data directory\n",
    "TARGET_DIR_NAME = f\"data/ai_agriculture\"\n",
    "\n",
    "# Setup training and test directories\n",
    "TARGET_DIR = Path(TARGET_DIR_NAME)\n",
    "TRAIN_DIR = TARGET_DIR / \"ot\" / \"ot\"\n",
    "VAL_DIR = TARGET_DIR / \"ot\" / \"ot\"\n",
    "TEST_DIR = TARGET_DIR / \"ot\" / \"ot\"\n",
    "ORIG_LABELS = TARGET_DIR / \"train2.csv\"\n",
    "TRAIN_LABELS = TARGET_DIR / \"train_split.csv\"\n",
    "VAL_LABELS = TARGET_DIR / \"val_split.csv\"\n",
    "TEST_LABELS = TARGET_DIR / \"test.csv\"\n",
    "TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create target model directory\n",
    "MODEL_DIR = Path(\"outputs\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set seeds\n",
    "SEED = 42\n",
    "set_seeds(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(df, target_count):\n",
    "\n",
    "    label_counts = df['label'].value_counts()\n",
    "    resampled_dfs = []\n",
    "\n",
    "    for label in sorted(label_counts.index):\n",
    "        group = df[df['label'] == label]\n",
    "        if len(group) < target_count:\n",
    "            # Oversample with replacement\n",
    "            group_resampled = resample(group, replace=True, n_samples=target_count, random_state=42)\n",
    "        else:\n",
    "            # Keep as is (or downsample if desired)\n",
    "            group_resampled = group\n",
    "        resampled_dfs.append(group_resampled)\n",
    "\n",
    "    # Concatenate all to form balanced train_df\n",
    "    return pd.concat(resampled_dfs).sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06134cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation size in percentage of the total size\n",
    "VAL_SIZE = 0.2\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(ORIG_LABELS)  # Make sure train.csv is in the same directory or provide the full path\n",
    "#df = resample_data(df, 25)\n",
    "\n",
    "# Split the dataframe\n",
    "train_df, val_df = train_test_split(df, test_size=VAL_SIZE, random_state=42, stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training data distribution\n",
    "sns.histplot(train_df['label'], bins=101, kde=False)\n",
    "plt.title('Histogram of train_df[\"label\"]')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279df5f",
   "metadata": {},
   "source": [
    "# 4. Specifying the Target Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01afed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate cuda benchmark\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if device == \"cuda\":\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c28c3",
   "metadata": {},
   "source": [
    "# 5. Preparing Dataloaders and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dataset_stats(dataloader):\n",
    "    min_val = float('inf')\n",
    "    max_val = float('-inf')\n",
    "    sum_vals = 0.0\n",
    "    sum_squared = 0.0\n",
    "    n_pixels = 0\n",
    "\n",
    "    for (images, _) in tqdm(dataloader, desc=\"Computing stats\"):\n",
    "        # Flatten to (batch_size, channels * H * W)\n",
    "        flat = images.view(images.size(0), -1)\n",
    "\n",
    "        min_val = min(min_val, flat.min().item())\n",
    "        max_val = max(max_val, flat.max().item())\n",
    "        sum_vals += flat.sum().item()\n",
    "        sum_squared += (flat ** 2).sum().item()\n",
    "        n_pixels += flat.numel()\n",
    "\n",
    "    mean = sum_vals / n_pixels\n",
    "    std = (sum_squared / n_pixels - mean ** 2) ** 0.5\n",
    "\n",
    "    return {\n",
    "        \"min\": min_val,\n",
    "        \"max\": max_val,\n",
    "        \"mean\": mean,\n",
    "        \"std\": std\n",
    "    }\n",
    "\n",
    "def compute_scaled_stats_2(dataloader):\n",
    "    s1, s2, n = 0.0, 0.0, 0\n",
    "    for imgs, _ in dataloader:\n",
    "        # imgs is (B, C, H, W) in [0,1] now\n",
    "        s1 += imgs.sum().item()\n",
    "        s2 += (imgs**2).sum().item()\n",
    "        n  += imgs.numel()\n",
    "    mu = s1 / n\n",
    "    sigma = (s2 / n - mu*mu)**0.5\n",
    "    return mu, sigma\n",
    "\n",
    "#mu_scaled, sigma_scaled = compute_scaled_stats(scaled_loader)\n",
    "#print(\"After scaling to [0,1]: mean =\", mu_scaled, \" std =\", sigma_scaled)\n",
    "\n",
    "def compute_max_log(dataloader):\n",
    "    max_val = -float('inf')\n",
    "    for batch, _ in dataloader:\n",
    "        max_val = max(max_val, batch.max().item())\n",
    "    return max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f30d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    'min': -0.011533993296325207,\n",
    "    'max': 28906.0,\n",
    "    'mean': 1385.8839183006537,\n",
    "    'std': 1117.384644793575\n",
    "    }\n",
    "\n",
    "stats_scaled = {\n",
    "    'mean': 0.05120476204006151,\n",
    "    'std': 0.0377356291529548\n",
    "    }\n",
    "\n",
    "MAX_RAW_VALUE = stats['max']\n",
    "MU_SCALED = stats_scaled['mean']\n",
    "SIGMA_SCALED = stats_scaled['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "IMG_SIZE_2 = 128\n",
    "BATCH_SIZE = 32\n",
    "AUG_LEVEL = 'high'\n",
    "\n",
    "# Augmentation transformations\n",
    "transforms_train = v2.Compose([\n",
    "    HyperspectralAugmentation(level=AUG_LEVEL, mode='train'),        \n",
    "    v2.Lambda(lambda t: t.float() / MAX_RAW_VALUE),\n",
    "    MeanStdNormalize(mean=MU_SCALED, std=SIGMA_SCALED),\n",
    "])\n",
    "transforms_val = v2.Compose([\n",
    "    HyperspectralAugmentation(level=AUG_LEVEL, mode='validation'),        \n",
    "    v2.Lambda(lambda t: t.float() / MAX_RAW_VALUE),\n",
    "    MeanStdNormalize(mean=MU_SCALED, std=SIGMA_SCALED),\n",
    "])\n",
    "\n",
    "# Dataloader\n",
    "train_dataloader, test_dataloader = create_dataloaders(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    test_dir=VAL_DIR,\n",
    "    train_labels=TRAIN_LABELS,\n",
    "    test_labels=VAL_LABELS,\n",
    "    train_transform=transforms_train,\n",
    "    test_transform=transforms_val,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    "    output_type='reg'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f05349",
   "metadata": {},
   "source": [
    "# 6. Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7237e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hyperspectral_batch(dataloader, num_images=10, num_channels=5):\n",
    "    \n",
    "    # Get a batch of data\n",
    "    data_iter = iter(dataloader)\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    min_vals = images.view(images.size(0), -1).min(dim=1)[0]\n",
    "    max_vals = images.view(images.size(0), -1).max(dim=1)[0]\n",
    "\n",
    "    # Make sure we don't exceed available images or channels\n",
    "    num_images = min(num_images, images.shape[0])\n",
    "    num_channels = min(num_channels, images.shape[1])\n",
    "    \n",
    "    fig, axes = plt.subplots(num_images, num_channels, figsize=(num_channels * 4, num_images * 4))\n",
    "    fig.suptitle(\"Hyperspectral Channels per Image\", fontsize=16)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        for j in range(num_channels):\n",
    "            ax = axes[i, j] if num_images > 1 else axes[j]\n",
    "            img = images[i, j].cpu().numpy()\n",
    "            ax.imshow(img, cmap='terrain')\n",
    "            #ax.set_title(f\"Label: {labels[i].item()}\")\n",
    "            ax.axis('off')\n",
    "    \n",
    "    #plt.savefig(\"augmentation.png\", bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_hyperspectral_batch(train_dataloader, num_images=2, num_channels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4530ea7",
   "metadata": {},
   "source": [
    "# 7. Creating a Spectral Vision Transformer (ViT) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac4c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ViT-Base model\n",
    "NUM_METRICS = 1 #only one target metric\n",
    "images, labels = next(iter(train_dataloader))\n",
    "KERNEL_SIZE = (images.shape[1], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6628e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom Vision Transformer Tiny (ViT-Tiny) model\n",
    "model = ViT(\n",
    "    img_size=IMG_SIZE_2,\n",
    "    in_channels=KERNEL_SIZE[0],\n",
    "    patch_size=8,\n",
    "    num_transformer_layers=4,\n",
    "    emb_dim=256,\n",
    "    mlp_size=512,\n",
    "    num_heads=8,\n",
    "    attn_dropout=0.1,\n",
    "    mlp_dropout=0.1,\n",
    "    emb_dropout=0.1,\n",
    "    num_classes=NUM_METRICS\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(BATCH_SIZE, KERNEL_SIZE[0], IMG_SIZE_2, IMG_SIZE_2),\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "    col_width=20,\n",
    "    row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a1291e",
   "metadata": {},
   "source": [
    "# 8. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MSEWithVarianceLoss(torch.nn.Module):\n",
    "    def __init__(self, lambda_var=3.67e-5):\n",
    "        super().__init__()\n",
    "        self.mse = torch.nn.MSELoss()\n",
    "        self.lambda_var = lambda_var  # weight for variance term\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        mse_loss = self.mse(predictions, targets)\n",
    "        variance = torch.var(predictions)\n",
    "\n",
    "        # We subtract variance because we want to maximize it (encourage spread)\n",
    "        variance_penalty = torch.clamp(self.lambda_var * variance, max=0.99 * mse_loss)\n",
    "        loss = mse_loss - variance_penalty\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1218f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "EPOCHS = 310 \n",
    "LR = 1e-6\n",
    "model_type=\"model_vit-t_reg_high_310_loss_epoch203\"\n",
    "model_name = model_type + \".pth\"\n",
    "\n",
    "# Create AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "# Create loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=LR/100)\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(SEED)\n",
    "\n",
    "# And train...\n",
    "\n",
    "# Instantiate the classification engine with the created model and the target device\n",
    "engine = RegressionEngine(\n",
    "    model=model,\n",
    "    color_map={'train': 'blue', 'test': 'red'},\n",
    "    log_verbose=True,\n",
    "    device=device)\n",
    "\n",
    "# Configure the training method\n",
    "results = engine.train(\n",
    "    target_dir=MODEL_DIR,                       # Directory where the model will be saved\n",
    "    model_name=model_name,                      # Name of the model\n",
    "    save_best_model=[\"loss\", \"last\", \"r2\"],     # Save the best models based on different criteria\n",
    "    keep_best_models_in_memory=False,           # Do not keep the models stored in memory for the sake of training time and memory efficiency\n",
    "    train_dataloader=train_dataloader,          # Train dataloader\n",
    "    test_dataloader=test_dataloader,            # Validation/test dataloader\n",
    "    apply_validation=True,                      # Enable validation step\n",
    "    optimizer=optimizer,                        # Optimizer\n",
    "    loss_fn=loss_fn,                            # Loss function    \n",
    "    scheduler=scheduler,                        # Scheduler\n",
    "    epochs=EPOCHS,                              # Total number of epochs\n",
    "    amp=True,                                   # Enable Automatic Mixed Precision (AMP)\n",
    "    enable_clipping=False,                      # Disable clipping on gradients, only useful if training becomes unestable\n",
    "    debug_mode=False,                           # Disable debug mode    \n",
    "    accumulation_steps=1,                       # Accumulation steps 2: effective batch size = batch_size x accumulation steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a6b08",
   "metadata": {},
   "source": [
    "Best performing model at epoch 203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26644fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning 1\n",
    "\n",
    "EPOCHS = 150\n",
    "LR = 1e-7\n",
    "model_type=\"model_vit-t_reg_high_310_from_203\"\n",
    "model_name = model_type + \".pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"model_vit-t_reg_high_310_loss_epoch203.pth\")))\n",
    "\n",
    "# Create AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "# Create loss function\n",
    "loss_fn = torch.nn.MSELoss()  # or L1Loss, SmoothL1Loss, HuberLoss, etc.\n",
    "\n",
    "# And scheduler\n",
    "#scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=LR/100)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=LR/100)\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(SEED)\n",
    "\n",
    "# And train...\n",
    "\n",
    "# Instantiate the classification engine with the created model and the target device\n",
    "engine = RegressionEngine(\n",
    "    model=model,\n",
    "    color_map={'train': 'blue', 'test': 'magenta'},\n",
    "    log_verbose=True,\n",
    "    device=device)\n",
    "\n",
    "# Configure the training method\n",
    "results = engine.train(\n",
    "    target_dir=MODEL_DIR,                       # Directory where the model will be saved\n",
    "    model_name=model_name,                      # Name of the model\n",
    "    save_best_model=[\"loss\", \"last\", \"r2\"],     # Save the best models based on different criteria\n",
    "    keep_best_models_in_memory=False,           # Do not keep the models stored in memory for the sake of training time and memory efficiency\n",
    "    train_dataloader=train_dataloader,          # Train dataloader\n",
    "    test_dataloader=test_dataloader,            # Validation/test dataloader\n",
    "    apply_validation=True,                      # Enable validation step\n",
    "    optimizer=optimizer,                        # Optimizer\n",
    "    loss_fn=loss_fn,                            # Loss function    \n",
    "    scheduler=scheduler,                        # Scheduler\n",
    "    epochs=EPOCHS,                              # Total number of epochs\n",
    "    amp=True,                                   # Enable Automatic Mixed Precision (AMP)\n",
    "    enable_clipping=False,                      # Disable clipping on gradients, only useful if training becomes unestable\n",
    "    debug_mode=False,                           # Disable debug mode    \n",
    "    accumulation_steps=1,                       # Accumulation steps 2: effective batch size = batch_size x accumulation steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning 2\n",
    "\n",
    "EPOCHS = 630\n",
    "LR = 1e-7\n",
    "model_type=\"model_vit-t_reg_high_1050\"\n",
    "model_name = model_type + \".pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, os.path.join(MODEL_DIR, 'checkpoint_epoch150.pth'))\n",
    "\n",
    "checkpoint = torch.load(os.path.join(MODEL_DIR, 'checkpoint_epoch150.pth'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Manually override LR in the optimizer\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = LR \n",
    "\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,        \n",
    "    T_mult=2,      \n",
    "    eta_min=LR/100 \n",
    ")\n",
    "\n",
    "# Instantiate the classification engine with the created model and the target device\n",
    "engine = RegressionEngine(\n",
    "    model=model,\n",
    "    color_map={'train': 'blue', 'test': 'orange'},\n",
    "    log_verbose=True,\n",
    "    device=device)\n",
    "\n",
    "# Configure the training method\n",
    "results = engine.train(\n",
    "    target_dir=MODEL_DIR,                       # Directory where the model will be saved\n",
    "    model_name=model_name,                      # Name of the model\n",
    "    save_best_model=[\"loss\", \"last\", \"r2\"],     # Save the best models based on different criteria\n",
    "    keep_best_models_in_memory=False,           # Do not keep the models stored in memory for the sake of training time and memory efficiency\n",
    "    train_dataloader=train_dataloader,          # Train dataloader\n",
    "    test_dataloader=test_dataloader,            # Validation/test dataloader\n",
    "    apply_validation=True,                      # Enable validation step\n",
    "    optimizer=optimizer,                        # Optimizer\n",
    "    loss_fn=loss_fn,                            # Loss function    \n",
    "    scheduler=scheduler,                        # Scheduler\n",
    "    epochs=EPOCHS,                              # Total number of epochs\n",
    "    amp=True,                                   # Enable Automatic Mixed Precision (AMP)\n",
    "    enable_clipping=False,                      # Disable clipping on gradients, only useful if training becomes unestable\n",
    "    debug_mode=False,                           # Disable debug mode    \n",
    "    accumulation_steps=1,                       # Accumulation steps 2: effective batch size = batch_size x accumulation steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning 3\n",
    "\n",
    "EPOCHS = 630\n",
    "LR = 5e-6\n",
    "model_type=\"model_vit-t_reg_high_1050_2\"\n",
    "model_name = model_type + \".pth\"\n",
    "\n",
    "checkpoint = torch.load(os.path.join(MODEL_DIR, 'checkpoint_epoch150.pth'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Create AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=LR,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,        \n",
    "    T_mult=2,      \n",
    "    eta_min=LR/100 \n",
    ")\n",
    "\n",
    "# Instantiate the classification engine with the created model and the target device\n",
    "engine = RegressionEngine(\n",
    "    model=model,\n",
    "    color_map={'train': 'blue', 'test': 'orange'},\n",
    "    log_verbose=True,\n",
    "    device=device)\n",
    "\n",
    "# Configure the training method\n",
    "results = engine.train(\n",
    "    target_dir=MODEL_DIR,                       # Directory where the model will be saved\n",
    "    model_name=model_name,                      # Name of the model\n",
    "    save_best_model=[\"loss\", \"last\", \"r2\"],     # Save the best models based on different criteria\n",
    "    keep_best_models_in_memory=False,           # Do not keep the models stored in memory for the sake of training time and memory efficiency\n",
    "    train_dataloader=train_dataloader,          # Train dataloader\n",
    "    test_dataloader=test_dataloader,            # Validation/test dataloader\n",
    "    apply_validation=True,                      # Enable validation step\n",
    "    optimizer=optimizer,                        # Optimizer\n",
    "    loss_fn=loss_fn,                            # Loss function    \n",
    "    scheduler=scheduler,                        # Scheduler\n",
    "    epochs=EPOCHS,                              # Total number of epochs\n",
    "    amp=True,                                   # Enable Automatic Mixed Precision (AMP)\n",
    "    enable_clipping=False,                      # Disable clipping on gradients, only useful if training becomes unestable\n",
    "    debug_mode=False,                           # Disable debug mode    \n",
    "    accumulation_steps=2,                       # Accumulation steps 2: effective batch size = batch_size x accumulation steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c5f56",
   "metadata": {},
   "source": [
    "# 9. Making predictions on the Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the model file with \"model_loss_epoch\" prefix and rename it\n",
    "def rename_model(model_name: str, new_name: str):\n",
    "    old_name = model_name[0]\n",
    "    os.rename(old_name, new_name)\n",
    "    print(f\"Renamed {old_name} to {new_name}\")\n",
    "\n",
    "#model_name = glob.glob(str(MODEL_DIR / f\"{model_type}_epoch*.pth\"))\n",
    "#new_model_name = str(MODEL_DIR / f\"{model_type}_2.pth\")\n",
    "#rename_model(model_name, new_model_name)\n",
    "\n",
    "# Transformations\n",
    "transforms = v2.Compose([        \n",
    "    v2.Lambda(lambda t: t.float() / MAX_RAW_VALUE),\n",
    "    MeanStdNormalize(mean=MU_SCALED, std=SIGMA_SCALED),\n",
    "])\n",
    "\n",
    "# Instantiate the model\n",
    "model = ViT(\n",
    "    img_size=IMG_SIZE_2,\n",
    "    in_channels=125, #images.shape[1],\n",
    "    patch_size=8,\n",
    "    num_transformer_layers=4, #12,\n",
    "    emb_dim=256, #1024,\n",
    "    mlp_size=512, #4096,\n",
    "    num_heads=8, #16,\n",
    "    attn_dropout=0.1, #0,\n",
    "    mlp_dropout=0.1,\n",
    "    emb_dropout=0.1,\n",
    "    num_classes=NUM_METRICS\n",
    ")\n",
    "\n",
    "# Load the model checkpoint weights\n",
    "model = Common().load_model(model, \"outputs\", f\"model_vit-t_reg_high_1050_2_epoch13.pth\").to(device)\n",
    "\n",
    "# Prepare the model in evaluation mode\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "test_df = pd.read_csv(TEST_LABELS)\n",
    "val_df = pd.read_csv(VAL_LABELS)\n",
    "\n",
    "ids    = []\n",
    "values = []\n",
    "submission_dict = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sample_id in test_df['id']:\n",
    "        # load the hyperspectral cube from .npy\n",
    "        npy_path = os.path.join(TEST_DIR, f\"{sample_id}\")\n",
    "        data = np.load(npy_path)                      # e.g. shape (128,128,125)\n",
    "        \n",
    "        image = data.astype(np.float32)\n",
    "\n",
    "        # Convert to tensor and permute to (C, H, W)\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1)  # Shape: (125, 128, 128)\n",
    "\n",
    "        # Resize spatial dimensions to (128, 128)\n",
    "        image = F.interpolate(image.unsqueeze(0), size=(128, 128), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Peform pre-processing        \n",
    "        image = transforms(image)\n",
    "\n",
    "        # Make predictions\n",
    "        out = model(image.to(device))\n",
    "        out = out.squeeze(0).cpu().numpy()        \n",
    "\n",
    "        # Scale the outputs to the original reange\n",
    "        out = out * 99.0 + 1\n",
    "                \n",
    "        ids.append(sample_id)\n",
    "        values.append(out.item())\n",
    "\n",
    "# build submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID':    ids,\n",
    "    'label': values\n",
    "})\n",
    "\n",
    "# save to CSV\n",
    "submission_df.to_csv(f\"submission_model_vit-t_reg_high_1050_2_epoch13.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
